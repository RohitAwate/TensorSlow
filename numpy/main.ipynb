{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(label: int) -> list:\n",
    "    code = [0] * 10\n",
    "    code[label] = 1\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(encode_label(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorslow as slow\n",
    "\n",
    "def load_data(path: str):\n",
    "    labels = os.listdir(path)\n",
    "    \n",
    "    X, y = [], []\n",
    "    for label in labels:\n",
    "        label_encoded = encode_label(int(label))\n",
    "\n",
    "        for sample in os.listdir(f\"{path}/{label}\")[:10]:\n",
    "            png = Image.open(f\"{path}/{label}/{sample}\")\n",
    "            arr = np.array(png)\n",
    "            X.append(arr.flatten())\n",
    "            y.append(label_encoded)\n",
    "\n",
    "    return slow.tensor(np.array(X)), slow.tensor(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(\"data/training\")\n",
    "X_test, y_test = load_data(\"data/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 784), (100, 10), (100, 784), (100, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "input_size = 28 * 28\n",
    "output_size = 10\n",
    "\n",
    "h1 = input_size // 2\n",
    "h2 = h1 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_binary(arr):\n",
    "    return np.all(np.logical_or(arr == 0, arr == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stochastic(arr):\n",
    "    # assert len(arr[arr < 0]) == 0\n",
    "    # assert len(arr[arr > 1]) == 0\n",
    "    \n",
    "    N, _ = arr.shape\n",
    "    return np.allclose(np.sum(arr, axis=1), np.ones(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = slow.exp(x - slow.max(x, axis=1, keepdims=True))\n",
    "    return e_x / slow.sum(e_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorslow.nn as nn\n",
    "from tensorslow.nn.activations import relu\n",
    "\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.layers.Dense(in_dim=input_size, out_dim=h1)\n",
    "        self.l2 = nn.layers.Dense(in_dim=h1, out_dim=h2)\n",
    "        self.l3 = nn.layers.Dense(in_dim=h2, out_dim=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l1_out = relu(self.l1(x))\n",
    "        l2_out = self.l2(l1_out)\n",
    "        l3_out = self.l3(l2_out)\n",
    "        return softmax(l3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10) (100, 1) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "net = FeedForwardNet()\n",
    "out = net(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(pred, target):\n",
    "    # assert is_binary(target), \"Target must contain all binary values\"\n",
    "    # assert is_stochastic(pred), \"Array must sum to 1\"\n",
    "    \n",
    "    return -slow.dot(target.T, slow.log(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = cross_entropy_loss(out, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Tensor.__init__.<locals>.<lambda> at 0x7f58146c1360>\n",
      "<function Tensor.__neg__.<locals>.neg_backward at 0x7f58146c2290>\n",
      "<function Tensor.dot.<locals>.dot_backward at 0x7f58146c2200>\n",
      "<function Tensor.__init__.<locals>.<lambda> at 0x7f58146c20e0>\n",
      "<function Tensor.log.<locals>.log_backward at 0x7f58146c2170>\n",
      "<function Tensor.__truediv__.<locals>.truediv_backward at 0x7f58146c1d80>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Code/TensorSlow/tensorslow/tensor.py:29\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_topsorted_graph():\n\u001b[1;32m     28\u001b[0m     \u001b[39mprint\u001b[39m(node\u001b[39m.\u001b[39mgrad_fn)\n\u001b[0;32m---> 29\u001b[0m     node\u001b[39m.\u001b[39;49mgrad_fn()\n",
      "File \u001b[0;32m~/Code/TensorSlow/tensorslow/tensor.py:94\u001b[0m, in \u001b[0;36mTensor.__truediv__.<locals>.truediv_backward\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m upstream_grad \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mgrad\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m self_local \u001b[39m*\u001b[39m upstream_grad\n\u001b[0;32m---> 94\u001b[0m other\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m other_local \u001b[39m*\u001b[39m upstream_grad\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (100,1) doesn't match the broadcast shape (100,10)"
     ]
    }
   ],
   "source": [
    "loss.mean().backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
